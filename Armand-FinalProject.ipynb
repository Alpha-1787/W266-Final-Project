{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/armand_kok/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0725 01:30:37.252146 140699083335488 deprecation_wrapper.py:119] From /home/armand_kok/anaconda3/lib/python3.7/site-packages/bert/optimization.py:87: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Used to pull data from Reddit\n",
    "import praw\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import statsmodels.formula.api\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import re\n",
    "\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "from nltk.corpus import brown\n",
    "import nltk\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.client import device_lib\n",
    "import tensorflow.keras as keras \n",
    "from tensorflow.keras.layers import Input, Lambda, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "import tensorflow_hub as hub\n",
    "import multiprocessing\n",
    "from google.cloud import bigquery\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import bert\n",
    "from bert import run_classifier\n",
    "from bert import optimization\n",
    "from bert import tokenization\n",
    "\n",
    "#nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[name: \"/device:CPU:0\"\n",
       " device_type: \"CPU\"\n",
       " memory_limit: 268435456\n",
       " locality {\n",
       " }\n",
       " incarnation: 6366769524787014769, name: \"/device:XLA_CPU:0\"\n",
       " device_type: \"XLA_CPU\"\n",
       " memory_limit: 17179869184\n",
       " locality {\n",
       " }\n",
       " incarnation: 2509712664769383742\n",
       " physical_device_desc: \"device: XLA_CPU device\", name: \"/device:XLA_GPU:0\"\n",
       " device_type: \"XLA_GPU\"\n",
       " memory_limit: 17179869184\n",
       " locality {\n",
       " }\n",
       " incarnation: 13793352719981433385\n",
       " physical_device_desc: \"device: XLA_GPU device\", name: \"/device:GPU:0\"\n",
       " device_type: \"GPU\"\n",
       " memory_limit: 14912199066\n",
       " locality {\n",
       "   bus_id: 1\n",
       "   links {\n",
       "   }\n",
       " }\n",
       " incarnation: 9921784099886283208\n",
       " physical_device_desc: \"device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\"]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check that the GPU is there\n",
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[22. 28.]\n",
      " [49. 64.]]\n",
      "[[22. 28.]\n",
      " [49. 64.]]\n"
     ]
    }
   ],
   "source": [
    "# Check that CPU and GPU are running\n",
    "with tf.device('/cpu:0'):\n",
    "    a_c = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[2, 3], name='a-cpu')\n",
    "    b_c = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2], name='b-cpu')\n",
    "    c_c = tf.matmul(a_c, b_c, name='c-cpu')\n",
    "    \n",
    "with tf.device('/gpu:0'):\n",
    "    a_g = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[2, 3], name='a-gpu')\n",
    "    b_g = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2], name='b-gpu')\n",
    "    c_g = tf.matmul(a_g, b_g, name='c-gpu')\n",
    "    \n",
    "with tf.Session(config=tf.ConfigProto(log_device_placement=True)) as sess:\n",
    "    print (sess.run(c_c))\n",
    "    print (sess.run(c_g))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read .sql that pulls comments\n",
    "fd = open('comments.sql', 'r')\n",
    "comment_sql = fd.read()\n",
    "fd.close()\n",
    "\n",
    "# Put query results into df\n",
    "comment_df = pd.read_gbq(comment_sql,\n",
    "                         project_id='w266-240122',\n",
    "                         dialect='standard')\n",
    "\n",
    "# Convert date into proper date/time\n",
    "comment_df['created_dt_tm'] = comment_df['created_utc'].apply(lambda x: dt.datetime.fromtimestamp(x))\n",
    "\n",
    "# Create field for month\n",
    "comment_df['created_dt_month'] = comment_df['created_dt_tm'].dt.to_period('M').dt.to_timestamp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/armand_kok/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:2785: DtypeWarning: Columns (0,1,2,4,5,6,9) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "#comment_df.to_csv('reddit_comments_2016_2019.csv')\n",
    "comment_df = pd.read_csv('reddit_comments_2016_2019.csv', parse_dates=['created_dt_month'])\n",
    "comment_df['body'] = comment_df['body'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read .sql that pulls comments\n",
    "fd = open('posts.sql', 'r')\n",
    "post_sql = fd.read()\n",
    "fd.close()\n",
    "\n",
    "post_df = pd.read_gbq(post_sql,\n",
    "                      project_id='w266-240122',\n",
    "                      dialect='standard')\n",
    "\n",
    "# Convert date into proper date/time\n",
    "post_df['created_dt_tm'] = post_df['created_utc'].apply(lambda x: dt.datetime.fromtimestamp(x))\n",
    "\n",
    "# Create field for month\n",
    "post_df['created_dt_month'] = post_df['created_dt_tm'].dt.to_period('M').dt.to_timestamp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#post_df.to_csv('reddit_posts_2016_2019.csv')\n",
    "post_df = pd.read_csv('reddit_posts_2016_2019.csv', parse_dates=['created_dt_month'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(comment_df, post_df, subreddit, lower=False):\n",
    "    \n",
    "    # TODO remove symbols, contractions\n",
    "    # TODO lowercase words?\n",
    "    # TODO Treat numbers as something else\n",
    "    # Add beginning and end of sentence?\n",
    "    # TODO how do we deal with stop words?\n",
    "    # UNK token\n",
    "    \n",
    "    # Body text from post dataframe\n",
    "    post_text = list(post_df[(post_df['is_self'] == True) &\n",
    "                             (~post_df['selftext'].isin(['[removed]', '[deleted]'])) &\n",
    "                             post_df['subreddit'].isin(subreddit)]['selftext'].unique())\n",
    "    \n",
    "    # Add in text from title\n",
    "    post_text += list(post_df[post_df['is_self'] == True]['title'].unique())\n",
    "    \n",
    "    # Add in text from post comments\n",
    "    post_text += list(comment_df[(comment_df['subreddit'].isin(subreddit)) & \n",
    "                                     (~comment_df['body'].isin(['[removed]', '[deleted]']))]['body'])\n",
    "    \n",
    "    # Put all text into dataframe and drop dupes\n",
    "    text_df = pd.DataFrame(post_text, columns=['text'])\n",
    "    text_df.drop_duplicates(inplace=True)\n",
    "    \n",
    "    # Tokenize at sentence level\n",
    "    text_df['sent_tokenized'] = text_df['text'].apply(nltk.sent_tokenize)\n",
    "    text_df['sent_count'] = text_df['sent_tokenized'].apply(lambda x: len(x))\n",
    "\n",
    "    # Put tokenized body into a list\n",
    "    sent_list = list(text_df[text_df['sent_count'] > 0]['sent_tokenized'].apply(pd.Series).stack().unique())\n",
    "\n",
    "    # Put list into dataframe\n",
    "    sent_df = pd.DataFrame(sent_list, columns=['sentence'])\n",
    "    \n",
    "    # lowercase\n",
    "    if lower == True:\n",
    "        sent_df['sentence'] = sent_df['sentence'].str.lower()\n",
    "\n",
    "    # Tokenize each sentence at the word level\n",
    "    sent_df['word_token'] = sent_df['sentence'].apply(nltk.word_tokenize)\n",
    "    \n",
    "    return sent_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_embedding(sent_df):\n",
    "    \n",
    "    # train word embedding\n",
    "    embedding = Word2Vec(list(sent_df['word_token']),\n",
    "                         size=100,\n",
    "                         window=5, \n",
    "                         min_count=5, \n",
    "                         negative=15, \n",
    "                         iter=10, workers=6)\n",
    "    \n",
    "    return embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data PreProcessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "comment_df['score_sentiment'] = comment_df['score'].apply(lambda x: 'positive' if x > 0 \n",
    "                                                          else 'negative' if x < 0 \n",
    "                                                          else 'neutral')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove uneeded columns\n",
    "comment_df = comment_df[['subreddit', 'body', 'created_dt_month', 'score', 'score_sentiment']].copy()\n",
    "\n",
    "# Remove comments that have been removed or deleted\n",
    "comment_df = comment_df[~comment_df['body'].isin(['[removed]', '[deleted]'])].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    5000.000000\n",
       "mean       49.359600\n",
       "std        77.260089\n",
       "min         1.000000\n",
       "25%        12.000000\n",
       "50%        26.000000\n",
       "75%        56.000000\n",
       "max      1436.000000\n",
       "Name: word_count, dtype: float64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_df['word_count'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df['score_sentiment'] = sample_df['score_sentiment'].apply(lambda x: 0 if x == 'negative' else 1)\n",
    "\n",
    "# split into train and test\n",
    "train_df, test_df = train_test_split(sample_df, test_size=.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_col = 'body'\n",
    "label_col = 'score_sentiment'\n",
    "label_list = [0, 1]\n",
    "\n",
    "# Use the InputExample class from BERT's run_classifier code to create examples from the data\n",
    "train_InputExamples = train_df.apply(lambda x: bert.run_classifier.InputExample(guid=None,\n",
    "                                                                                text_a = x[data_col],\n",
    "                                                                                text_b = None, \n",
    "                                                                                label = x[label_col]), axis = 1)\n",
    "\n",
    "test_InputExamples = test_df.apply(lambda x: bert.run_classifier.InputExample(guid=None, \n",
    "                                                                              text_a = x[data_col], \n",
    "                                                                              text_b = None, \n",
    "                                                                              label = x[label_col]), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘bert_model’: File exists\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "./\n",
      "./saved_model.pb\n",
      "./variables/\n",
      "./variables/variables.index\n",
      "./variables/variables.data-00000-of-00001\n",
      "100  388M  100  388M    0     0  66.5M      0  0:00:05  0:00:05 --:--:-- 71.5M\n",
      "./tfhub_module.pb\n",
      "./assets/\n",
      "./assets/vocab.txt\n"
     ]
    }
   ],
   "source": [
    "# Download BERT to a local directory\n",
    "!mkdir bert_model\n",
    "\n",
    "# Download the module, and uncompress it to the destination folder. \n",
    "!curl -L \"https://tfhub.dev/google/bert_uncased_L-12_H-768_A-12/1?tf-hub-format=compressed\" | tar -zxvC bert_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tokenizer_from_hub_module():\n",
    "    \"\"\"Get the vocab file and casing info from the Hub module.\"\"\"\n",
    "    with tf.Graph().as_default():\n",
    "        bert_model = hub.Module('bert_model')\n",
    "        tokenization_info = bert_model(signature=\"tokenization_info\", as_dict=True)\n",
    "        with tf.Session() as sess:\n",
    "            vocab_file, do_lower_case = sess.run([tokenization_info['vocab_file'],\n",
    "                                                  tokenization_info['do_lower_case']])\n",
    "\n",
    "    return bert.tokenization.FullTokenizer(vocab_file=vocab_file, do_lower_case=do_lower_case)\n",
    "\n",
    "tokenizer = create_tokenizer_from_hub_module()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll set sequences to be at most 128 tokens long.\n",
    "MAX_SEQ_LENGTH = 64\n",
    "\n",
    "# Convert our train and test features to InputFeatures that BERT understands.\n",
    "train_features = bert.run_classifier.convert_examples_to_features(train_InputExamples, \n",
    "                                                                  label_list,\n",
    "                                                                  MAX_SEQ_LENGTH,\n",
    "                                                                  tokenizer)\n",
    "\n",
    "test_features = bert.run_classifier.convert_examples_to_features(test_InputExamples,\n",
    "                                                                 label_list,\n",
    "                                                                 MAX_SEQ_LENGTH,\n",
    "                                                                 tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(is_predicting, input_ids, input_mask, segment_ids, labels, num_labels):\n",
    "    \"\"\"Creates a classification model.\"\"\"\n",
    "    bert_module = hub.Module('bert_model', \n",
    "                             trainable=True)\n",
    "    bert_inputs = dict(input_ids=input_ids, input_mask=input_mask, segment_ids=segment_ids)\n",
    "    bert_outputs = bert_module(inputs=bert_inputs, signature=\"tokens\", as_dict=True)\n",
    "\n",
    "    # Use \"pooled_output\" for classification tasks on an entire sentence.\n",
    "    # Use \"sequence_outputs\" for token-level output.\n",
    "    output_layer = bert_outputs[\"pooled_output\"]\n",
    "\n",
    "    hidden_size = output_layer.shape[-1].value\n",
    "\n",
    "    # Create our own layer to tune for politeness data.\n",
    "    output_weights = tf.get_variable(\"output_weights\", \n",
    "                                     [num_labels, hidden_size],\n",
    "                                     initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "\n",
    "    output_bias = tf.get_variable(\"output_bias\", [num_labels], initializer=tf.zeros_initializer())\n",
    "\n",
    "    with tf.variable_scope(\"loss\"):\n",
    "        \n",
    "        # Dropout helps prevent overfitting\n",
    "        output_layer = tf.nn.dropout(output_layer, keep_prob=0.9)\n",
    "\n",
    "        logits = tf.matmul(output_layer, output_weights, transpose_b=True)\n",
    "        logits = tf.nn.bias_add(logits, output_bias)\n",
    "        log_probs = tf.nn.log_softmax(logits, axis=-1)\n",
    "\n",
    "        # Convert labels into one-hot encoding\n",
    "        one_hot_labels = tf.one_hot(labels, depth=num_labels, dtype=tf.float32)\n",
    "\n",
    "        predicted_labels = tf.squeeze(tf.argmax(log_probs, axis=-1, output_type=tf.int32))\n",
    "        # If we're predicting, we want predicted labels and the probabiltiies.\n",
    "        if is_predicting:\n",
    "            return (predicted_labels, log_probs)\n",
    "\n",
    "        # If we're train/eval, compute loss between predicted and actual label\n",
    "        per_example_loss = -tf.reduce_sum(one_hot_labels * log_probs, axis=-1)\n",
    "        loss = tf.reduce_mean(per_example_loss)\n",
    "        return (loss, predicted_labels, log_probs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_fn_builder actually creates our model function\n",
    "# using the passed parameters for num_labels, learning_rate, etc.\n",
    "def model_fn_builder(num_labels, learning_rate, num_train_steps, num_warmup_steps):\n",
    "    \"\"\"Returns `model_fn` closure for TPUEstimator.\"\"\"\n",
    "    def model_fn(features, labels, mode, params):  # pylint: disable=unused-argument\n",
    "        \"\"\"The `model_fn` for TPUEstimator.\"\"\"\n",
    "\n",
    "        input_ids = features[\"input_ids\"]\n",
    "        input_mask = features[\"input_mask\"]\n",
    "        segment_ids = features[\"segment_ids\"]\n",
    "        label_ids = features[\"label_ids\"]\n",
    "\n",
    "        is_predicting = (mode == tf.estimator.ModeKeys.PREDICT)\n",
    "        \n",
    "        # TRAIN and EVAL\n",
    "        if not is_predicting:\n",
    "            (loss, predicted_labels, log_probs) = create_model(is_predicting,\n",
    "                                                               input_ids, \n",
    "                                                               input_mask, \n",
    "                                                               segment_ids,\n",
    "                                                               label_ids, \n",
    "                                                               num_labels)\n",
    "            train_op = bert.optimization.create_optimizer(loss, \n",
    "                                                          learning_rate, \n",
    "                                                          num_train_steps,\n",
    "                                                          num_warmup_steps, \n",
    "                                                          use_tpu=False)\n",
    "            # Calculate evaluation metrics. \n",
    "            def metric_fn(label_ids, predicted_labels):\n",
    "                accuracy = tf.metrics.accuracy(label_ids, predicted_labels)\n",
    "                f1_score = tf.contrib.metrics.f1_score(\n",
    "                    label_ids,\n",
    "                    predicted_labels)\n",
    "                auc = tf.metrics.auc(\n",
    "                    label_ids,\n",
    "                    predicted_labels)\n",
    "                recall = tf.metrics.recall(\n",
    "                    label_ids,\n",
    "                    predicted_labels)\n",
    "                precision = tf.metrics.precision(\n",
    "                    label_ids,\n",
    "                    predicted_labels) \n",
    "                true_pos = tf.metrics.true_positives(\n",
    "                    label_ids,\n",
    "                    predicted_labels)\n",
    "                true_neg = tf.metrics.true_negatives(\n",
    "                    label_ids,\n",
    "                    predicted_labels)   \n",
    "                false_pos = tf.metrics.false_positives(\n",
    "                    label_ids,\n",
    "                    predicted_labels)  \n",
    "                false_neg = tf.metrics.false_negatives(\n",
    "                    label_ids,\n",
    "                    predicted_labels)\n",
    "                return {\"eval_accuracy\": accuracy,\n",
    "                        \"f1_score\": f1_score,\n",
    "                        \"auc\": auc,\n",
    "                        \"precision\": precision,\n",
    "                        \"recall\": recall,\n",
    "                        \"true_positives\": true_pos,\n",
    "                        \"true_negatives\": true_neg,\n",
    "                        \"false_positives\": false_pos,\n",
    "                        \"false_negatives\": false_neg}\n",
    "\n",
    "            eval_metrics = metric_fn(label_ids, predicted_labels)\n",
    "\n",
    "            if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "                return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)\n",
    "            else:\n",
    "                return tf.estimator.EstimatorSpec(mode=mode,\n",
    "                                                  loss=loss,\n",
    "                                                  eval_metric_ops=eval_metrics)\n",
    "        else:\n",
    "            (predicted_labels, log_probs) = create_model(is_predicting,\n",
    "                                                         input_ids, \n",
    "                                                         input_mask,\n",
    "                                                         segment_ids,\n",
    "                                                         label_ids, \n",
    "                                                         num_labels)\n",
    "\n",
    "            predictions = {'probabilities': log_probs,\n",
    "                           'labels': predicted_labels}\n",
    "            return tf.estimator.EstimatorSpec(mode, predictions=predictions)\n",
    "\n",
    "    # Return the actual model function in the closure\n",
    "    return model_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute train and warmup steps from batch size\n",
    "# These hyperparameters are copied from this colab notebook (https://colab.sandbox.google.com/github/tensorflow/tpu/blob/master/tools/colab/bert_finetuning_with_cloud_tpus.ipynb)\n",
    "BATCH_SIZE = 32\n",
    "LEARNING_RATE = 2e-5\n",
    "NUM_TRAIN_EPOCHS = 3.0\n",
    "# Warmup is a period of time where hte learning rate \n",
    "# is small and gradually increases--usually helps training.\n",
    "WARMUP_PROPORTION = 0.1\n",
    "# Model configs\n",
    "SAVE_CHECKPOINTS_STEPS = 500\n",
    "SAVE_SUMMARY_STEPS = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute # train and warmup steps from batch size\n",
    "num_train_steps = int(len(train_features) / BATCH_SIZE * NUM_TRAIN_EPOCHS)\n",
    "num_warmup_steps = int(num_train_steps * WARMUP_PROPORTION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘model_output’: File exists\r\n"
     ]
    }
   ],
   "source": [
    "!mkdir model_output\n",
    "OUTPUT_DIR = 'model_output'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify outpit directory and number of checkpoint steps to save\n",
    "run_config = tf.estimator.RunConfig(\n",
    "    model_dir=OUTPUT_DIR,\n",
    "    save_summary_steps=SAVE_SUMMARY_STEPS,\n",
    "    save_checkpoints_steps=SAVE_CHECKPOINTS_STEPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fn = model_fn_builder(\n",
    "  num_labels=len(label_list),\n",
    "  learning_rate=LEARNING_RATE,\n",
    "  num_train_steps=num_train_steps,\n",
    "  num_warmup_steps=num_warmup_steps)\n",
    "\n",
    "estimator = tf.estimator.Estimator(\n",
    "  model_fn=model_fn,\n",
    "  config=run_config,\n",
    "  params={\"batch_size\": BATCH_SIZE})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an input function for training. drop_remainder = True for using TPUs.\n",
    "train_input_fn = bert.run_classifier.input_fn_builder(\n",
    "    features=train_features,\n",
    "    seq_length=MAX_SEQ_LENGTH,\n",
    "    is_training=True,\n",
    "    drop_remainder=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning Training!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/armand_kok/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/gradients_util.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/home/armand_kok/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/gradients_util.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "W0722 06:11:01.865738 139670156429120 deprecation.py:323] From /home/armand_kok/anaconda3/lib/python3.7/site-packages/tensorflow/python/training/saver.py:1066: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file utilities to get mtimes.\n",
      "W0722 06:12:31.778995 139670156429120 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 78 vs previous value: 78. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
      "W0722 06:13:17.794290 139670156429120 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 86 vs previous value: 86. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
      "W0722 06:17:36.321920 139670156429120 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 131 vs previous value: 131. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
      "W0722 06:17:59.266176 139670156429120 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 135 vs previous value: 135. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
      "W0722 06:21:03.458581 139670156429120 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 167 vs previous value: 167. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training took time  0:27:52.699804\n"
     ]
    }
   ],
   "source": [
    "print(f'Beginning Training!')\n",
    "current_time = datetime.now()\n",
    "estimator.train(input_fn=train_input_fn, max_steps=num_train_steps)\n",
    "print(\"Training took time \", datetime.now() - current_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input_fn = run_classifier.input_fn_builder(\n",
    "    features=test_features,\n",
    "    seq_length=MAX_SEQ_LENGTH,\n",
    "    is_training=False,\n",
    "    drop_remainder=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/armand_kok/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/gradients_util.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/home/armand_kok/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/gradients_util.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'auc': 0.5,\n",
       " 'eval_accuracy': 0.9208,\n",
       " 'f1_score': 0.9587671,\n",
       " 'false_negatives': 0.0,\n",
       " 'false_positives': 99.0,\n",
       " 'loss': 0.27497643,\n",
       " 'precision': 0.9208,\n",
       " 'recall': 1.0,\n",
       " 'true_negatives': 0.0,\n",
       " 'true_positives': 1151.0,\n",
       " 'global_step': 351}"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator.evaluate(input_fn=test_input_fn, steps=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9208"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df['score_sentiment'].sum()/test_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPrediction(in_sentences):\n",
    "  labels = [\"Negative\", \"Positive\"]\n",
    "  input_examples = [run_classifier.InputExample(guid=\"\", text_a = x, text_b = None, label = 0) for x in in_sentences] # here, \"\" is just a dummy label\n",
    "  input_features = run_classifier.convert_examples_to_features(input_examples, label_list, MAX_SEQ_LENGTH, tokenizer)\n",
    "  predict_input_fn = run_classifier.input_fn_builder(features=input_features, seq_length=MAX_SEQ_LENGTH, is_training=False, drop_remainder=False)\n",
    "  predictions = estimator.predict(predict_input_fn)\n",
    "  return [(sentence, prediction['probabilities'], labels[prediction['labels']]) for sentence, prediction in zip(in_sentences, predictions)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ELMo Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘elmo_model’: File exists\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "assets/\n",
      "saved_model.pb\n",
      "tfhub_module.pb\n",
      "variables/\n",
      "variables/variables.index\n",
      "variables/variables.data-00000-of-00001\n",
      "100  331M  100  331M    0     0  53.1M      0  0:00:06  0:00:06 --:--:-- 62.4M\n"
     ]
    }
   ],
   "source": [
    "# Download ELMo to a local directory\n",
    "!mkdir elmo_model\n",
    "\n",
    "# Download the module, and uncompress it to the destination folder. \n",
    "!curl -L \"https://tfhub.dev/google/elmo/2?tf-hub-format=compressed\" | tar -zxvC elmo_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df = comment_df[comment_df['subreddit'].isin(['progressive', 'democrats'])][['body', 'score_sentiment']]\n",
    "sample_df = sample_df[sample_df['score_sentiment'].isin(['positive', 'negative'])]\n",
    "sample_df = sample_df.sample(n=50000)\n",
    "\n",
    "sample_df.reset_index(drop=True, inplace=True)\n",
    "sample_df['word_tokens'] = sample_df['body'].apply(nltk.word_tokenize)\n",
    "sample_df['word_count'] = sample_df['word_tokens'].apply(lambda x: len(x))\n",
    "sample_df.loc[sample_df['score_sentiment']=='positive', 'score_sentiment'] = 0\n",
    "sample_df.loc[sample_df['score_sentiment']=='negative', 'score_sentiment'] = 1\n",
    "\n",
    "sample_df = sample_df[sample_df['word_count'] <= 150].copy().reset_index(drop=True)\n",
    "#sample_df = sample_df.sample(n=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_df = sample_df[sample_df['score_sentiment'] == 1].sample(n=400)\n",
    "pos_df = sample_df[sample_df['score_sentiment'] == 0].sample(n=400)\n",
    "train_df = pd.concat([neg_df, pos_df]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_contraction(text):\n",
    "    contraction_patterns = [ (r'won\\'t', 'will not'), (r'can\\'t', 'can not'), (r'i\\'m', 'i am'), (r'ain\\'t', 'is not'), (r'(\\w+)\\'ll', '\\g<1> will'), (r'(\\w+)n\\'t', '\\g<1> not'),\n",
    "                         (r'(\\w+)\\'ve', '\\g<1> have'), (r'(\\w+)\\'s', '\\g<1> is'), (r'(\\w+)\\'re', '\\g<1> are'), (r'(\\w+)\\'d', '\\g<1> would'), (r'&', 'and'), (r'dammit', 'damn it'), (r'dont', 'do not'), (r'wont', 'will not') ]\n",
    "    patterns = [(re.compile(regex), repl) for (regex, repl) in contraction_patterns]\n",
    "    for (pattern, repl) in patterns:\n",
    "        (text, count) = re.subn(pattern, repl, text)\n",
    "    return text\n",
    "def replace_links(text, filler=' '):\n",
    "        text = re.sub(r'((http|https)\\:\\/\\/)?[a-zA-Z0-9\\.\\/\\?\\:@\\-_=#]+\\.([a-zA-Z]){2,6}([a-zA-Z0-9\\.\\&\\/\\?\\:@\\-_=#])*',\n",
    "                      filler, text).strip()\n",
    "        return text\n",
    "def remove_numbers(text):\n",
    "    text = ''.join([i for i in text if not i.isdigit()])\n",
    "    return text\n",
    "\n",
    "def cleanText(text):\n",
    "    text = text.strip().replace(\"\\n\", \" \").replace(\"\\r\", \" \")\n",
    "    text = replace_contraction(text)\n",
    "    text = replace_links(text, \"link\")\n",
    "    text = remove_numbers(text)\n",
    "    text = re.sub(r'[,!@#$%^&*)(|/><\";:.?\\'\\\\}{]',\"\",text)\n",
    "    text = text.lower()\n",
    "    return text\n",
    "\n",
    "X = np.array(train_df['body'].apply(cleanText))\n",
    "y = np.array(train_df['score_sentiment'], dtype='int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def elmo_vectors(x):\n",
    "    elmo_model = hub.Module('elmo_model')\n",
    "    embeddings = elmo_model(x, signature=\"default\", as_dict=True)['default']\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        sess.run([tf.global_variables_initializer(), tf.tables_initializer()])\n",
    "        return sess.run(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_train = [X[i:i+100] for i in range(0,X.shape[0],100)]\n",
    "elmo_train = [elmo_vectors(x) for x in list_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = np.array(elmo_train)\n",
    "test = test.reshape((800, 1024))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True, ...,  True,  True,  True])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[0] == elmo_train[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.1316358 , -0.30224773, -0.03127664, ...,  0.03492352,\n",
       "        0.4176932 ,  0.04573776], dtype=float32)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(elmo_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.15895168, -0.26038992, -0.07098972, ...,  0.01008534,\n",
       "        0.4314407 ,  0.06160729], dtype=float32)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 1024)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "elmo_embeddings = embeddings.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(52, 1024)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elmo_embeddings[2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_embeddings = np.array(np.zeros((1,1024)))\n",
    "elmo_model = hub.Module('elmo_model')\n",
    "for i in np.arange(0, X.shape[0], 100):\n",
    "    elmo_model = hub.Module('elmo_model')\n",
    "    embed_list = elmo_model(X[i: i+100], signature=\"default\", as_dict=True)['default']\n",
    "    with tf.Session() as session:\n",
    "        session.run([tf.global_variables_initializer(), tf.tables_initializer()])\n",
    "        embeddings = session.run(embed_list)\n",
    "    X_embeddings = np.append(X_embeddings, embeddings, axis=0)\n",
    "X_embeddings = X_embeddings[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_test = sample_df.sample(n=200).reset_index(drop=True)\n",
    "X_test = np.array(sample_test['body'].apply(cleanText))\n",
    "y_test = np.array(sample_test['score_sentiment'], dtype='int')\n",
    "\n",
    "X_test_embeddings = np.array(np.zeros((1,1024)))\n",
    "elmo_model = hub.Module('elmo_model')\n",
    "for i in np.arange(0, X_test.shape[0], 100):\n",
    "    elmo_model = hub.Module('elmo_model')\n",
    "    embed_list = elmo_model(X_test[i: i+100], signature=\"default\", as_dict=True)['default']\n",
    "    with tf.Session() as session:\n",
    "        session.run([tf.global_variables_initializer(), tf.tables_initializer()])\n",
    "        embeddings = session.run(embed_list)\n",
    "    X_test_embeddings = np.append(X_test_embeddings, embeddings, axis=0)\n",
    "X_test_embeddings = X_test_embeddings[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      0.97      0.98       405\n",
      "          1       0.97      0.98      0.98       395\n",
      "\n",
      "avg / total       0.98      0.98      0.98       800\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier(max_depth=15)\n",
    "model.fit(X_embeddings, y)\n",
    "print(classification_report(model.predict(X_embeddings), y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.62      0.90      0.73       125\n",
      "          1       0.29      0.07      0.11        75\n",
      "\n",
      "avg / total       0.50      0.59      0.50       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(model.predict(X_test_embeddings), y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       1.00      0.92      0.96       200\n",
      "        1.0       0.00      0.00      0.00         0\n",
      "\n",
      "avg / total       1.00      0.92      0.96       200\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/armand_kok/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(np.zeros(y_test.shape[0]), y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_accuracy 0.6274074074074074\n",
      "test_accuracy 0.4666666666666667\n"
     ]
    }
   ],
   "source": [
    "print('train_accuracy', accuracy_score(model.predict(X_train), y_train))\n",
    "print('test_accuracy', accuracy_score(model.predict(X_test), y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "elmo_model = hub.Module('elmo_model')\n",
    "embedding = elmo_model(X[0:100], signature=\"default\", as_dict=True)['default']\n",
    "    \n",
    "with tf.Session() as session:\n",
    "    session.run([tf.global_variables_initializer(), tf.tables_initializer()])\n",
    "    X_embedding = session.run(embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_13 (InputLayer)        [(None, 1)]               0         \n",
      "_________________________________________________________________\n",
      "lambda_12 (Lambda)           (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 256)               262400    \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 262,657\n",
      "Trainable params: 262,657\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def ELMoEmbedding(x):\n",
    "    embed = hub.Module(\"elmo_model\")\n",
    "    return embed(tf.squeeze(tf.cast(x, tf.string)), signature=\"default\", as_dict=True)[\"default\"]\n",
    "\n",
    "def build_model(): \n",
    "    input_text = Input(shape=(1,), dtype=\"string\")\n",
    "    embedding = Lambda(ELMoEmbedding, output_shape=(1024, ))(input_text)\n",
    "    drop = keras.layers.Dropout(rate=0.5)(embedding)\n",
    "    dense = Dense(256, activation='relu', kernel_regularizer=keras.regularizers.l2(0.001))(embedding)\n",
    "    pred = Dense(1, activation='sigmoid')(dense)\n",
    "    model = Model(inputs=[input_text], outputs=pred)\n",
    "    model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model_elmo = build_model()\n",
    "model_elmo.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1600 samples, validate on 400 samples\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function BaseSession._Callable.__del__ at 0x7f0edba5d6a8>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/armand_kok/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\", line 1473, in __del__\n",
      "    self._session._session, self._handle)\n",
      "tensorflow.python.framework.errors_impl.CancelledError: (None, None, 'Session has been closed.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1536/1600 [===========================>..] - ETA: 0s - loss: 1.3972 - acc: 0.5749"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function BaseSession._Callable.__del__ at 0x7f0edba5d6a8>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/armand_kok/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\", line 1473, in __del__\n",
      "    self._session._session, self._handle)\n",
      "tensorflow.python.framework.errors_impl.CancelledError: (None, None, 'Session has been closed.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1600/1600 [==============================] - 27s 17ms/sample - loss: 1.3816 - acc: 0.5775 - val_loss: 1.6452 - val_acc: 0.0225\n",
      "Epoch 2/5\n",
      "1600/1600 [==============================] - 26s 16ms/sample - loss: 1.0341 - acc: 0.6106 - val_loss: 1.3663 - val_acc: 0.0425\n",
      "Epoch 3/5\n",
      "1600/1600 [==============================] - 25s 16ms/sample - loss: 0.9806 - acc: 0.5881 - val_loss: 1.1168 - val_acc: 0.2150\n",
      "Epoch 4/5\n",
      "1600/1600 [==============================] - 25s 15ms/sample - loss: 0.9347 - acc: 0.6175 - val_loss: 1.9251 - val_acc: 0.0175\n",
      "Epoch 5/5\n",
      "1600/1600 [==============================] - 25s 16ms/sample - loss: 0.9324 - acc: 0.6000 - val_loss: 1.5085 - val_acc: 0.0200\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as session:\n",
    "    K.set_session(session)\n",
    "    session.run(tf.global_variables_initializer())  \n",
    "    session.run(tf.tables_initializer())\n",
    "    history = model_elmo.fit(X, y, epochs=5, batch_size=64, validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4000 samples, validate on 1000 samples\n",
      "Epoch 1/2\n",
      "4000/4000 [==============================] - 68s 17ms/sample - loss: 0.6895 - precision_4: 0.0755 - val_loss: 0.4697 - val_precision_4: 0.0000e+00\n",
      "Epoch 2/2\n",
      "4000/4000 [==============================] - 65s 16ms/sample - loss: 0.5248 - precision_4: 0.0732 - val_loss: 0.3822 - val_precision_4: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as session:\n",
    "    K.set_session(session)\n",
    "    session.run(tf.global_variables_initializer())  \n",
    "    session.run(tf.tables_initializer())\n",
    "    history = model_elmo.fit(X, y, epochs=2, batch_size=64, validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_lexicon(filename):\n",
    "    \"\"\"\n",
    "    Load a file from Bing Liu's sentiment lexicon\n",
    "    (https://www.cs.uic.edu/~liub/FBS/sentiment-analysis.html), containing\n",
    "    English words in Latin-1 encoding.\n",
    "    \n",
    "    One file contains a list of positive words, and the other contains\n",
    "    a list of negative words. The files contain comment lines starting\n",
    "    with ';' and blank lines, which should be skipped.\n",
    "    \"\"\"\n",
    "    lexicon = []\n",
    "    with open(filename, encoding='latin-1') as infile:\n",
    "        for line in infile:\n",
    "            line = line.rstrip()\n",
    "            if line and not line.startswith(';'):\n",
    "                lexicon.append(line)\n",
    "    return lexicon\n",
    "\n",
    "pos_words = load_lexicon('positive-words.txt')\n",
    "neg_words = load_lexicon('negative-words.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'word_embedding' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-60297874b00f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0me\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mword_embedding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0membedding_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvectors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0membedding_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex2word\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mpos_vectors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membedding_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpos_words\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'word_embedding' is not defined"
     ]
    }
   ],
   "source": [
    "e = word_embedding\n",
    "embedding_df = pd.DataFrame(e.wv.vectors)\n",
    "embedding_df.index = e.wv.index2word\n",
    "\n",
    "pos_vectors = embedding_df.reindex(index=pos_words).dropna()\n",
    "neg_vectors = embedding_df.reindex(index=neg_words).dropna()\n",
    "\n",
    "vectors = pd.concat([pos_vectors, neg_vectors])\n",
    "targets = np.array([1 for entry in pos_vectors.index] + [-1 for entry in neg_vectors.index])\n",
    "labels = list(pos_vectors.index) + list(neg_vectors.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7634854771784232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:152: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "train_vectors, test_vectors, train_targets, test_targets, train_labels, test_labels = \\\n",
    "train_test_split(vectors, targets, labels, test_size=0.1, random_state=0)\n",
    "model = SGDClassifier(loss='log', random_state=0, n_iter=100)\n",
    "model.fit(train_vectors, train_targets)\n",
    "\n",
    "print(accuracy_score(model.predict(test_vectors), test_targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sabotage</th>\n",
       "      <td>-2.115922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>undocumented</th>\n",
       "      <td>-2.074377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>slowly</th>\n",
       "      <td>-0.855885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>slaughter</th>\n",
       "      <td>-0.999751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>debilitating</th>\n",
       "      <td>0.157101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dirt</th>\n",
       "      <td>-2.300752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mindless</th>\n",
       "      <td>-1.347088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>strong</th>\n",
       "      <td>13.202846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nuisance</th>\n",
       "      <td>-0.612164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deceiving</th>\n",
       "      <td>-0.432331</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              sentiment\n",
       "sabotage      -2.115922\n",
       "undocumented  -2.074377\n",
       "slowly        -0.855885\n",
       "slaughter     -0.999751\n",
       "debilitating   0.157101\n",
       "dirt          -2.300752\n",
       "mindless      -1.347088\n",
       "strong        13.202846\n",
       "nuisance      -0.612164\n",
       "deceiving     -0.432331"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def vecs_to_sentiment(vecs):\n",
    "    # predict_log_proba gives the log probability for each class\n",
    "    predictions = model.predict_log_proba(vecs)\n",
    "\n",
    "    # To see an overall positive vs. negative classification in one number,\n",
    "    # we take the log probability of positive sentiment minus the log\n",
    "    # probability of negative sentiment.\n",
    "    return predictions[:, 1] - predictions[:, 0]\n",
    "\n",
    "\n",
    "def words_to_sentiment(words):\n",
    "    vecs = embedding_df.loc[words].dropna()\n",
    "    log_odds = vecs_to_sentiment(vecs)\n",
    "    return pd.DataFrame({'sentiment': log_odds}, index=vecs.index)\n",
    "\n",
    "\n",
    "# Show 20 examples from the test set\n",
    "words_to_sentiment(test_labels).iloc[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "TOKEN_RE = re.compile(r\"\\w.*?\\b\")\n",
    "# The regex above finds tokens that start with a word-like character (\\w), and continues\n",
    "# matching characters (.+?) until the next word break (\\b). It's a relatively simple\n",
    "# expression that manages to extract something very much like words from text.\n",
    "\n",
    "\n",
    "def text_to_sentiment(text):\n",
    "    tokens = [token.casefold() for token in TOKEN_RE.findall(text)]\n",
    "    sentiments = words_to_sentiment(tokens)\n",
    "    return sentiments['sentiment'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-5.745474703785556"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_to_sentiment('Trump')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.1328254916227443"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_to_sentiment('Obama')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.2195910751765513"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_to_sentiment('Biden')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25.283264240040666"
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_to_sentiment('Progressive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08479791049252694"
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_to_sentiment('Mexican')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('trump', 0.8514634370803833),\n",
       " ('Putin', 0.6282497644424438),\n",
       " ('he', 0.5907704830169678),\n",
       " ('Trumpski', 0.590567946434021),\n",
       " ('tRump', 0.579472541809082),\n",
       " ('him', 0.5785919427871704),\n",
       " ('Russia', 0.5719641447067261),\n",
       " ('Bernie', 0.5676500797271729),\n",
       " ('Whitaker', 0.5499702095985413),\n",
       " ('Obama', 0.5409168004989624)]"
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e.wv.most_similar('Trump')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('tRump', 0.6996694207191467),\n",
       " ('wrist', 0.6700129508972168),\n",
       " ('stuffed', 0.6529507040977478),\n",
       " ('Bitch', 0.6497117280960083),\n",
       " ('trumpty', 0.6405702829360962),\n",
       " ('Pai', 0.6387597322463989),\n",
       " ('graham', 0.6387059688568115),\n",
       " ('Ajit', 0.638285219669342),\n",
       " ('tRUMP', 0.6369954347610474),\n",
       " ('Haley', 0.6360580325126648)]"
      ]
     },
     "execution_count": 419,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e.wv.most_similar('Donny')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('impeaching', 0.6418150067329407),\n",
       " ('Impeach', 0.6205568909645081),\n",
       " ('Supporters', 0.6122241020202637),\n",
       " ('Supporter', 0.6121823787689209),\n",
       " ('Tower', 0.5998998880386353),\n",
       " ('Organization', 0.5910106897354126),\n",
       " ('Pence', 0.5623512864112854),\n",
       " ('President', 0.5594371557235718),\n",
       " ('Fred', 0.5535253882408142),\n",
       " ('administration', 0.5455576777458191)]"
      ]
     },
     "execution_count": 420,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e.wv.most_similar('Donald')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ELMo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "  0  331M    0   415    0     0    369      0  10d 21h  0:00:01  10d 21h   369x assets/\n",
      "x saved_model.pb\n",
      "x tfhub_module.pb\n",
      "x variables/\n",
      "x variables/variables.index\n",
      "100  331M  100  331M    0     0  2054k      0  0:02:45  0:02:45 --:--:-- 2379k 2614kk      0  0:02:59  0:01:26  0:01:33 2755k   0  2087k      0  0:02:42  0:01:43  0:00:59 3369k      0  0:02:41  0:01:51  0:00:50 2300k  0:01:56  0:00:44 2391k0:02:44  0:02:25  0:00:19 2082k\n",
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/control_flow_ops.py:3632: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0719 22:37:02.743443 4547675584 deprecation.py:323] From /anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/control_flow_ops.py:3632: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0719 22:37:03.826928 4547675584 saver.py:1483] Saver not created because there are no variables in the graph to restore\n"
     ]
    }
   ],
   "source": [
    "# Initialize elmo\n",
    "elmo = hub.Module('module_elmo', trainable=True)\n",
    "embeddings = elmo(['Trump thinks criticism of his misogynistic remarks is a \"political correctness\" problem. Nope, its a pervasive #sexism problem. #GOPDebate'], signature=\"default\", as_dict=True)['elmo']\n",
    "\n",
    "# Get word embedding\n",
    "with tf.Session() as session:\n",
    "    session.run([tf.global_variables_initializer(), tf.tables_initializer()])\n",
    "    message_embeddings = session.run(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'message_embeddings' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-fff5e2a857bc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmessage_embeddings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'message_embeddings' is not defined"
     ]
    }
   ],
   "source": [
    "message_embeddings[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questions\n",
    "* Sentiment analysis labeled data\n",
    "* How would we go about scoring the performance of our models?\n",
    "    * I proposed to use the scores that are available on the reddit\n",
    "* Should we train the sentiment classifier at a sentence or post level?\n",
    "    * Each post may contain multiple sentences\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
